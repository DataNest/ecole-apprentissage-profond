{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is highly inspired from https://github.com/Lasagne/Recipes/blob/master/examples/lstm_text_generation.py\n",
    "http://lasagne.readthedocs.io/en/latest/modules/layers/recurrent.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import lasagne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasagne.random.set_rng(np.random.RandomState(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sequence Length\n",
    "SEQ_LENGTH = 20\n",
    "\n",
    "# Number of units in the two hidden (LSTM) layers\n",
    "N_HIDDEN = 512\n",
    "\n",
    "# Optimization learning rate\n",
    "LEARNING_RATE = .01\n",
    "\n",
    "# All gradients above this will be clipped\n",
    "GRAD_CLIP = 100\n",
    "\n",
    "# How often should we check the output?\n",
    "PRINT_FREQ = 100\n",
    "\n",
    "# Number of epochs to train the net\n",
    "NUM_EPOCHS = 50\n",
    "\n",
    "# Batch Size\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request #For downloading the sample text file. You won't need this if you are providing your own file.\n",
    "try:\n",
    "    in_text = urllib.request.urlopen('https://s3.amazonaws.com/text-datasets/nietzsche.txt').read()\n",
    "    #in_text = open('your_file.txt', 'r').read()\n",
    "    #in_text = in_text.decode(\"utf-8-sig\").encode(\"utf-8\")\n",
    "    in_text = in_text.decode(\"utf-8\")\n",
    "except Exception as e:\n",
    "    print(\"Please verify the location of the input file/URL.\")\n",
    "    print(\"A sample txt file can be downloaded from https://s3.amazonaws.com/text-datasets/nietzsche.txt\")\n",
    "    raise IOError('Unable to Read Text')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-processing consists in retrieving the list of symbols occuring in the text and for each symbol, convert it into an unique index. This index will be used to create an one-hot representation of the symbol that will be the input of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique symbols: 84\n",
      "Number of symbols in the dataset: 600893\n"
     ]
    }
   ],
   "source": [
    "chars = list(set(in_text))\n",
    "data_size, vocab_size = len(in_text), len(chars)\n",
    "char_to_ix = { ch:i for i,ch in enumerate(chars) }\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars) }\n",
    "print('Number of unique symbols: {}'.format(vocab_size))\n",
    "print('Number of symbols in the dataset: {}'.format(data_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following auxiliary function creates a minibatch in a 3D tensor (batch_size,SEQ_LENGTH,vocab_size).\n",
    "For each datapoint (fixed first coordinate of the 3D matrix), there is a matrix of dimension (SEQ_LENGTH,vocab_size)\n",
    "where each line contains the one-hot vector representing the character at the associated position. Notice that the sequences have all the same length (SEQ_LENGTH), which can covers many sentences. TODO: verify if it implies truncated backprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_data(p, batch_size = BATCH_SIZE, data=in_text, return_target=True):\n",
    "    \"\"\"Return a minibatch compatible with the input of the model and the associated targets\n",
    "    \n",
    "\n",
    "    Keyword arguments:\n",
    "    p -- The index of the character to begin to read\n",
    "    batch_size -- The number of datapoints in the current batch\n",
    "    data -- The whole text\n",
    "    return_target -- Create the targets (next character) associated to the sequences\n",
    "    \"\"\"\n",
    "    x = np.zeros((batch_size,SEQ_LENGTH,vocab_size))\n",
    "    y = np.zeros(batch_size)\n",
    "    \n",
    "    for n in range(batch_size):\n",
    "        ptr = n\n",
    "        for i in range(SEQ_LENGTH):\n",
    "            x[n,i,char_to_ix[data[p+ptr+i]]] = 1.\n",
    "        if(return_target):\n",
    "            y[n] = char_to_ix[data[p+ptr+SEQ_LENGTH]]\n",
    "    return x, np.array(y,dtype='int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layers to construct recurrent networks. Recurrent layers can be used similarly to feed-forward layers except that the input shape is expected to be (batch_size, sequence_length, num_inputs). By setting the first two dimensions as None, we are allowing them to vary. They correspond to batch size and sequence length, so we will be able to feed in batches of varying size with sequences of varying length. If `only_return_final` is set, it only returns the final sequential output (e.g. for tasks where a single target value for the entire sequence is desired). In this case, Theano makes an optimization which saves memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, we build an input layer\n",
    "# Recurrent layers expect input of shape\n",
    "# (batch size, SEQ_LENGTH, num_features)\n",
    "\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None, vocab_size))\n",
    "\n",
    "# We now build the LSTM layer which takes l_in as the input layer\n",
    "# We clip the gradients at GRAD_CLIP to prevent the problem of exploding gradients. \n",
    "\n",
    "l_forward_1 = lasagne.layers.LSTMLayer(\n",
    "    l_in, num_units=N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "    nonlinearity=lasagne.nonlinearities.tanh, only_return_final=True)\n",
    "\n",
    "l_shp = lasagne.layers.ReshapeLayer(l_forward_1, (-1, N_HIDDEN))\n",
    "\n",
    "# The output of l_forward_2 of shape (batch_size, N_HIDDEN) is then passed through the softmax nonlinearity to \n",
    "# create probability distribution of the prediction\n",
    "# The output of this stage is (batch_size, vocab_size)\n",
    "#l_out = lasagne.layers.DenseLayer(l_forward_2, num_units=vocab_size, W = lasagne.init.Normal(), nonlinearity=lasagne.nonlinearities.softmax)\n",
    "l_out = lasagne.layers.DenseLayer(l_shp, num_units=vocab_size, W = lasagne.init.Normal(), nonlinearity=lasagne.nonlinearities.softmax)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building network ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Building network ...\")\n",
    "   \n",
    "# First, we build the network, starting with an input layer\n",
    "# Recurrent layers expect input of shape\n",
    "# (batch size, SEQ_LENGTH, num_features)\n",
    "\n",
    "l_in = lasagne.layers.InputLayer(shape=(None, None, vocab_size))\n",
    "\n",
    "# We now build the LSTM layer which takes l_in as the input layer\n",
    "# We clip the gradients at GRAD_CLIP to prevent the problem of exploding gradients. \n",
    "\n",
    "l_forward_1 = lasagne.layers.LSTMLayer(\n",
    "    l_in, num_units=N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "    nonlinearity=lasagne.nonlinearities.tanh)\n",
    "\n",
    "l_forward_2 = lasagne.layers.LSTMLayer(\n",
    "    l_forward_1, num_units=N_HIDDEN, grad_clipping=GRAD_CLIP,\n",
    "    nonlinearity=lasagne.nonlinearities.tanh,\n",
    "    only_return_final=True)\n",
    "\n",
    "# The output of l_forward_2 of shape (batch_size, N_HIDDEN) is then passed through the softmax nonlinearity to \n",
    "# create probability distribution of the prediction\n",
    "# The output of this stage is (batch_size, vocab_size)\n",
    "l_out = lasagne.layers.DenseLayer(l_forward_2, num_units=vocab_size, W = lasagne.init.Normal(), nonlinearity=lasagne.nonlinearities.softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Theano tensor for the targets\n",
    "target_values = T.ivector('target_output')\n",
    "    \n",
    "# lasagne.layers.get_output produces a variable for the output of the net\n",
    "network_output = lasagne.layers.get_output(l_out)\n",
    "\n",
    "# The loss function is calculated as the mean of the (categorical) cross-entropy between the prediction and target.\n",
    "cost = T.nnet.categorical_crossentropy(network_output,target_values).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the \n",
    "http://lasagne.readthedocs.io/en/latest/modules/updates.html?highlight=update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing updates ...\n",
      "Compiling functions ...\n"
     ]
    }
   ],
   "source": [
    "# Retrieve all parameters from the network\n",
    "all_params = lasagne.layers.get_all_params(l_out,trainable=True)\n",
    "\n",
    "# Compute AdaGrad updates for training\n",
    "print(\"Computing updates ...\")\n",
    "updates = lasagne.updates.adagrad(cost, all_params, LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Theano functions for training and computing cost\n",
    "print(\"Compiling functions ...\")\n",
    "train = theano.function([l_in.input_var, target_values], cost, updates=updates, allow_input_downcast=True)\n",
    "compute_cost = theano.function([l_in.input_var, target_values], cost, allow_input_downcast=True)\n",
    "\n",
    "# In order to generate text from the network, we need the probability distribution of the next character given\n",
    "# the state of the network and the input (a seed).\n",
    "# In order to produce the probability distribution of the prediction, we compile a function called probs. \n",
    "    \n",
    "probs = theano.function([l_in.input_var],network_output,allow_input_downcast=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "The phrase is set using the variable generation_phrase.\n",
    "The optional input \"N\" is used to set the number of characters of text to predict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "generation_phrase = \"The meaning of life is\" #This phrase will be used as seed to generate text.\n",
    "\n",
    "def predict(N=200):\n",
    "    \"\"\"\n",
    "    Output a sequence of characters of lenght N according to the current model\n",
    "\n",
    "    Keyword arguments:\n",
    "    N -- number of characters to output\n",
    "    \"\"\"\n",
    "    assert(len(generation_phrase)>=SEQ_LENGTH)\n",
    "    sample_ix = []\n",
    "    x,_ = gen_data(len(generation_phrase)-SEQ_LENGTH, 1, generation_phrase,0)\n",
    "\n",
    "    for i in range(N):\n",
    "        # Pick the character that got assigned the highest probability\n",
    "        ix = np.argmax(probs(x).ravel())\n",
    "        # Alternatively, to sample from the distribution instead:\n",
    "        # ix = np.random.choice(np.arange(vocab_size), p=probs(x).ravel())\n",
    "        sample_ix.append(ix)\n",
    "        x[:,0:SEQ_LENGTH-1,:] = x[:,1:,:]\n",
    "        x[:,SEQ_LENGTH-1,:] = 0\n",
    "        x[0,SEQ_LENGTH-1,sample_ix[-1]] = 1. \n",
    "\n",
    "    random_snippet = generation_phrase + ''.join(ix_to_char[ix] for ix in sample_ix)    \n",
    "    print(\"----\\n %s \\n----\" % random_snippet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "Seed used for text generation is: The meaning of life is\n",
      "----\n",
      " The meaning of life is                                                                                                                                                                                                         \n",
      "----\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "print(\"Training ...\")\n",
    "print(\"Seed used for text generation is: \" + generation_phrase)\n",
    "p = 0\n",
    "for it in range(int(data_size * NUM_EPOCHS / BATCH_SIZE)):\n",
    "    try_it_out() # Generate text using the p^th character as the start. \n",
    "            \n",
    "    avg_cost = 0;\n",
    "    for i in range(PRINT_FREQ):\n",
    "        x,y = gen_data(p)\n",
    "\n",
    "        p += SEQ_LENGTH + BATCH_SIZE - 1 \n",
    "        if(p+BATCH_SIZE+SEQ_LENGTH >= data_size):\n",
    "            print('Carriage Return')\n",
    "            p = 0;\n",
    "\n",
    "        avg_cost += train(x, y)\n",
    "        print(i)\n",
    "    print(\"Epoch {} average loss = {}\".format(it*1.0*PRINT_FREQ/data_size*BATCH_SIZE, avg_cost / PRINT_FREQ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
